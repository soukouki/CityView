
# --- templates ---
x-airflow-common: &x-airflow-common
    build: ./airflow
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres@db:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres@db:5432/airflow
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.default
      SERVICE_CAPTURE_URL: http://service-capture:5000
      SERVICE_ESTIMATE_URL: http://service-estimate:5001
      SERVICE_TILE_CUT_URL: http://service-tile-cut:5002
      SERVICE_TILE_MERGE_URL: http://service-tile-merge:5003
      SERVICE_TILE_COMPRESS_URL: http://service-tile-compress:5004
      BACKEND_INTERNAL_URL: http://backend:8002
      STORAGE_URL: http://storage
      PAKSET_SIZE: ${PAKSET_SIZE}
      TILE_SIZE: ${TILE_SIZE}
      DELTA: ${DELTA}
      MAP_TILES_X: ${MAP_TILES_X}
      MAP_TILES_Y: ${MAP_TILES_Y}
      IMAGE_WIDTH: ${IMAGE_WIDTH}
      IMAGE_HEIGHT: ${IMAGE_HEIGHT}
      IMAGE_MARGIN_WIDTH: ${IMAGE_MARGIN_WIDTH}
      IMAGE_MARGIN_HEIGHT: ${IMAGE_MARGIN_HEIGHT}
      TILE_QUALITY_MAX_ZOOM: ${TILE_QUALITY_MAX_ZOOM}
      TILE_QUALITY_OTHER: ${TILE_QUALITY_OTHER}
      TZ: ${TZ}
      AIRFLOW__CORE__DAG_FILE_PROCESSOR_TIMEOUT: 120
      AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT: 120
    volumes:
      - ./airflow/dags:/opt/airflow/dags:ro
      - airflow-logs:/opt/airflow/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

services:
  # --- Infrastructure Layer ---
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
      POSTGRES_DB: gamedb
    volumes:
      - ./volume-db:/var/lib/postgresql/data
      - ./db/init-scripts:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - ./volume-redis:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  storage:
    image: nginx:alpine
    volumes:
      - ./volume-storage:/data
      - ./nginx/webdav.conf:/etc/nginx/conf.d/default.conf:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1/"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # --- Application Layer ---
  backend:
    build: ./backend
    environment:
      DATABASE_URL: postgres://postgres@db:5432/gamedb
      AIRFLOW_API_URL: http://airflow-webserver:8080/api/v1
      STORAGE_URL: http://storage
    ports:
      - "8000:8000" # メイン
      - "8001:8001" # 管理画面
      - "8002:8002" # Airflow連携用内部API
    volumes:
      - ./volume-backend-logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # --- Airflow Layer ---
  airflow-init:
    <<: *x-airflow-common
    command: >
      bash -c "
      airflow db migrate &&
      airflow users create --username admin --password admin --role Admin --email admin@example.com --firstname Airflow --lastname Admin &&
      tail -f /dev/null
      "

  airflow-webserver:
    <<: *x-airflow-common
    command: webserver
    ports:
      - "8003:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *x-airflow-common
    command: scheduler

  # --- Airflow Worker Layer ---
  airflow-worker-capture:
    <<: *x-airflow-common
    command: celery worker -q capture --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-estimate:
    <<: *x-airflow-common
    command: celery worker -q estimate --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-cut:
    <<: *x-airflow-common
    command: celery worker -q tile_cut --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-merge:
    <<: *x-airflow-common
    command: celery worker -q tile_merge --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-compress:
    <<: *x-airflow-common
    command: celery worker -q tile_compress --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-cleanup:
    <<: *x-airflow-common
    command: celery worker -q tile_cleanup --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-capture-cleanup:
    <<: *x-airflow-common
    command: celery worker -q screenshot_cleanup --concurrency 2
    deploy:
      replicas: 2

  # --- Processing Service Layer ---
  service-capture:
    build: ./service-capture
    environment:
      STORAGE_URL: http://storage
      GAME_EXECUTABLE: simutrans-extended
      PAKSET_NAME: ${PAKSET_NAME}
      PAKSET_SIZE: ${PAKSET_SIZE}
      CAPTURE_SCREEN_WIDTH: ${CAPTURE_WIDTH}
      CAPTURE_SCREEN_HEIGHT: ${CAPTURE_HEIGHT}
      CAPTURE_CROP_WIDTH: ${IMAGE_WIDTH}
      CAPTURE_CROP_HEIGHT: ${IMAGE_HEIGHT}
      CAPTURE_CROP_OFFSET_X: ${CROP_OFFSET_X}
      CAPTURE_CROP_OFFSET_Y: ${CROP_OFFSET_Y}
      CAPTURE_TTL_SECONDS: 60
      GAME_BOOT_TIMEOUT_SECONDS: 180
      GAME_BOOT_POLL_INTERVAL_SECONDS: 1
      GAME_BOOT_CHECK_X: 256 # この座標が黒いかどうかで起動完了を判定する
      GAME_BOOT_CHECK_Y: 256
    volumes:
      - ./volume-storage:/data
      - ./volume-bin:/app/bin
      - ./volume-save:/root/simutrans
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 2
    restart: unless-stopped

  service-estimate:
    build: ./service-estimate
    environment:
      STORAGE_URL: http://storage
      IMAGE_MARGIN_WIDTH: ${IMAGE_MARGIN_WIDTH}
      IMAGE_MARGIN_HEIGHT: ${IMAGE_MARGIN_HEIGHT}
      IMAGE_WIDTH: ${IMAGE_WIDTH}
      IMAGE_HEIGHT: ${IMAGE_HEIGHT}
    volumes:
      - ./volume-storage:/data
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-cut:
    build: ./service-tile-cut
    environment:
      STORAGE_URL: http://storage
      TILE_SIZE: ${TILE_SIZE}
      CACHE_TTL: 60
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-merge:
    build: ./service-tile-merge
    environment:
      STORAGE_URL: http://storage
      TILE_SIZE: ${TILE_SIZE}
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-compress:
    build: ./service-tile-compress
    environment:
      STORAGE_URL: http://storage
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

volumes:
  airflow-logs:
    driver: local
