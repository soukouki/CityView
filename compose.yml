services:
  # --- Infrastructure Layer ---
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_HOST_AUTH_METHOD: trust
      POSTGRES_DB: gamedb
    volumes:
      - ./volume-db:/var/lib/postgresql/data
      - ./db/init-scripts:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - ./volume-redis:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  storage:
    image: nginx:alpine
    volumes:
      - ./volume-storage:/data
      - ./nginx/webdav.conf:/etc/nginx/conf.d/default.conf:ro
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1/"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # --- Application Layer ---
  backend:
    build: ./backend
    environment:
      DATABASE_URL: postgres://postgres@db:5432/gamedb
      AIRFLOW_API_URL: http://airflow-webserver:8080/api/v1
      STORAGE_URL: http://storage
    ports:
      - "8000:8000" # メイン
      - "8001:8001" # 管理画面
      - "8002:8002" # Airflow連携用内部API
    volumes:
      - ./volume-backend-logs:/app/logs
    depends_on:
      db:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    restart: unless-stopped

  # --- Airflow Layer ---
  airflow-common: &airflow-common
    build: ./airflow
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres@db:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://postgres@db:5432/airflow
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.default
      BACKEND_INTERNAL_URL: http://backend:8002
    volumes:
      - ./airflow/dags:/opt/airflow/dags:ro
      - ./volume-airflow-logs:/opt/airflow/logs
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - "8003:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # --- Airflow Worker Layer ---
  airflow-worker-capture:
    <<: *airflow-common
    command: celery worker -q capture --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-coords:
    <<: *airflow-common
    command: celery worker -q coords --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-cut:
    <<: *airflow-common
    command: celery worker -q tile_cut --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-merge:
    <<: *airflow-common
    command: celery worker -q tile_merge --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-compress:
    <<: *airflow-common
    command: celery worker -q tile_compress --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-tile-cleanup:
    <<: *airflow-common
    command: celery worker -q tile_cleanup --concurrency 2
    deploy:
      replicas: 2

  airflow-worker-screenshot-cleanup:
    <<: *airflow-common
    command: celery worker -q screenshot_cleanup --concurrency 2
    deploy:
      replicas: 2

  # --- Processing Service Layer ---
  service-capture:
    build: ./service-capture
    environment:
      STORAGE_URL: http://storage
      GAME_EXECUTABLE: simutrans-extended
      PAKSET_NAME: Pak128.Britain-Ex
      PAKSET_SIZE: 128
    volumes:
      - ./volume-storage:/data
      - ./volume-bin:/app/bin
      - ./volume-save:/root/simutrans
    deploy:
      replicas: 2
    restart: unless-stopped

  service-coords:
    build: ./service-coords
    environment:
      STORAGE_URL: http://storage
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-cut:
    build: ./service-tile-cut
    environment:
      STORAGE_URL: http://storage
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-merge:
    build: ./service-tile-merge
    environment:
      STORAGE_URL: http://storage
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped

  service-tile-compress:
    build: ./service-tile-compress
    environment:
      STORAGE_URL: http://storage
      AVIF_QUALITY: "30"
    volumes:
      - ./volume-storage:/data
    deploy:
      replicas: 2
    restart: unless-stopped
